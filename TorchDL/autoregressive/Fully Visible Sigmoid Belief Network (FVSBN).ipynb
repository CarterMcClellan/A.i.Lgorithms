{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Rule\n",
    "Take any old distribution\n",
    "$$p(x_1, \\ldots, x_n)$$\n",
    "The chain rule states\n",
    "$$ p(x_1, \\ldots, x_n) = \\prod_{i=1}^n p(x_i ~|~ x_1, \\ldots, x_{i-1}) = \\prod_{i=1}^n p(x_i ~|~ x_{< i})$$\n",
    "The nifty thing about this is that we can use it to represent any possible distribution, as a table, for example consider representing the joint probability distribution of 2 bernoulli random variables\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "p(x_1 = 1) & p(x_1 = 0)\\\\\n",
    "p(x_2 = 1 | x_1 = 1) & p(x_2 = 1 | x_1 = 1) & p(x_2 = 0 | x_1 = 1) & p(x_2 = 0 | x_1 = 0)\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "And immediately we see the problem, the table explodes at rate $d^n$, where $d$ is the number of possible values a random variable can have and $n$ is the number of random variables, but thats kinda close to what we want for a generator model. We want to learn some distribution of the training data, and to emulate that, so we want some discounted version of that table ^^, which doesn't take up so much space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Simplification\n",
    "Instead of filling out a table consider a function like this\n",
    "$$p_{\\theta_i}(x_i ~|~ x_{< i}) = Bern(f(x_{<i})$$\n",
    "Which maps the conditional distribution to some output between 0 and 1\n",
    "$$p_{\\theta_i}(x_i ~|~ x_{< i}) \\to Bern(f(x_{<i})) \\in \\{0, 1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Dataloaders\n",
    "None of this is all that important its just getting the a dataset, and transforming the data to make it more ammenable to low compute resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from barbar import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want the image values to be between 0 and 1, and we we want them to be tensors\n",
    "# resize the images to be 18 by 18 to make the generation process easier\n",
    "trans = transforms.Compose([transforms.Grayscale(), transforms.Resize((18,18)), transforms.ToTensor()])\n",
    "mnist_loader = torch.utils.data.DataLoader(datasets.MNIST(root='./data', train=True, download=True, \n",
    "                                                          transform=trans), shuffle=True)\n",
    "MNIST_SIZE = 18 \n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f80228bc950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx, (img, label) = next(enumerate(mnist_loader))\n",
    "plt.imshow(img[0][0], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Visible Sigmoid Belief Network (FVSBN)\n",
    "Using the above **Bernoulli Simplification** choose, \n",
    "$$f(x_{x<i}) = \\sigma(\\alpha \\cdot x_1 + \\ldots + \\alpha \\cdot x_{i-1}) \\tag{1}$$\n",
    "Where\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{x}}$$\n",
    "\n",
    "### FVSBN in Practice\n",
    "Now lets apply this to MNIST. \n",
    "\n",
    "**Data Prep**\n",
    "\n",
    "Our method does not use convolution, it takes the input image as a vector\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x_{1,1} & \\ldots & x_{1, 28}\\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "x{28, 1} & \\ldots & x_{28, 28}\n",
    "\\end{pmatrix} \n",
    "\\to\n",
    "\\begin{pmatrix}\n",
    "x_{1,1} & \\ldots & x_{28, 28}\\\\\n",
    "\\end{pmatrix} \n",
    "$$\n",
    "Additionally our model is trying to predict if a pixel is 0 or 1, so the input vector is binarized\n",
    "\n",
    "**Generation**\n",
    "\n",
    "Our function \n",
    "$$f(x_{x<i}) = \\sigma(\\alpha \\cdot x_1 + \\ldots + \\alpha \\cdot x_{i-1})$$\n",
    "is supposed to predict the *ith* pixel as a result of the previous set of pixels (this is why the method is called *autoregressive*. \n",
    "\n",
    "Fitting a model to learn $\\alpha$ involves training $dim(image)^2$ linear layers in a neural net. The first layer predicting $pixel_{1,2}$, the last layer predicting $pixel_{28, 28}$. Note *what about the first pixel*. The first pixel has no prior and thus is chosen at random from the domain which in this case is just $\\{0, 1\\}$. Note that our function (1), returns the *probability* that a given pixel value 1, thus \n",
    "\n",
    "$$pixel_{i} = Bern(f(x_{x<i}))$$\n",
    "\n",
    "\n",
    "**Discrimination/ Loss**\n",
    "But how do you tell if the generated output is any good or not? The simplest course of action is to compute the log likelihood, that is, if our guess or generated output is $Bern(f(x_{x<i}))$, and the ground truth value, or the pixel value observed in that particular training image is $\\overline{\\text{pixel i}}$, then the log likelihood is\n",
    "$$\n",
    "\\text{log likelihood}(\\overline{\\text{pixel i}}) = \\overline{\\text{pixel i}} * \\log_e(Bern(f(x_{x<i})) + \\epsilon) + (1 - \\overline{\\text{pixel i}}) * \\log_e(1 - Bern(f(x_{x<i})) + \\epsilon)\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "So lets break down what (2) is doing and why we need $\\epsilon$.\n",
    "\n",
    "Our generator is either correct or not correct. So lets see what happens when its correct\n",
    "- (pixel i = 1, guess $\\approx$ 1) or (pixel i= 0, guess $\\approx$ 0). in either of these cases we return something which is pretty close to 0, which for loss means, hey we did a pretty good job with guessing that pixel\n",
    "\n",
    "When we are wrong though\n",
    "- (pixel i = 1, guess $\\not =$ 1) or (pixel i= 0, guess $\\not =$ 0) we get the opposite effect. The further our guess is away from being correct the smaller thing we are taking the logarithm of, which is where $\\epsilon$ comes into play. If we wanan make sure our $\\log_e$ doesn't spit out infinity we have to add an additionally small term onto to our guess to make it ever so slighly greater than 0.\n",
    "\n",
    "Now our loss at the moment is only being measured on a per pixel basis, we want to sum over all the pixels, giving a net loss looking something like \n",
    "$$\\sum_{i=2}^{\\text{dim(image)}} \\text{log likelihood}(\\overline{\\text{pixel i}}) \\tag{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = torch.Tensor([1e-10]).to(device)\n",
    "def log_pmf(pixel_val, guess):\n",
    "    '''\n",
    "    equation (2) from above\n",
    "    \n",
    "    note that this takes the probability that a pixel is 1 (guess), not the pixel value itself\n",
    "    \n",
    "    pixel val is the ground truth value\n",
    "    '''\n",
    "    guess = guess.to(device)\n",
    "    return pixel_val * torch.log(guess + epsilon) + (1. - pixel_val) * torch.log(1. - guess + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FVSBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FVSBN, self).__init__()\n",
    "        \n",
    "        # each of these layers represents the inner bit of equation (1)\n",
    "        layers = []\n",
    "        for i in range(1, MNIST_SIZE**2):\n",
    "            layers += [nn.Linear(i, 1)]\n",
    "        \n",
    "        self.models = nn.Sequential(*layers)\n",
    "        \n",
    "        # HACK (almost all the MNIST images have a first pixel \n",
    "        # value of 0)\n",
    "        self.x1 = torch.Tensor([0])\n",
    "    \n",
    "    def forward(self, image):\n",
    "        \n",
    "        # DATA PREP\n",
    "        # flatten out our image mat into a vector\n",
    "        image = image.view(-1, MNIST_SIZE**2)\n",
    "        # binarize our our image vector\n",
    "        image = torch.where(image < 0.5, torch.tensor(0.).to(device), torch.tensor(1.).to(device))\n",
    "        \n",
    "        # setting the first pixel\n",
    "        # we do this outside the loop because we have no weight matrix for it\n",
    "        probability = torch.sigmoid(self.x1)\n",
    "        logpx = log_pmf(image[:, 0:1], probability)\n",
    "        \n",
    "        # generating the rest of our pixels using our learned weights\n",
    "        # note:\n",
    "        #   next x represents using eq (1) - generating the ith pixel\n",
    "        #   predictated on pixels [0, i-1] (slicing in python is non inclusive thats why it says i)\n",
    "        \n",
    "        # then using eq (3) to calculate our loss on this image generation\n",
    "        for i in range(1, MNIST_SIZE**2):\n",
    "            next_x = torch.sigmoid(self.models[i-1](image[:, 0:i]))\n",
    "            logpx += log_pmf(image[:, i:i+1], next_x)\n",
    "        \n",
    "        return logpx\n",
    "    \n",
    "    def sample(self):\n",
    "        with torch.no_grad():\n",
    "            # always set our initial pixel to be 0\n",
    "            initial_pixel = self.x1\n",
    "            complete_image = torch.zeros(1, MNIST_SIZE**2, device=device)\n",
    "            complete_image[:, 0:1] = initial_pixel\n",
    "            \n",
    "            # as mentioned before, now that the model is fit\n",
    "            # to eq (1), we use this weights to guess the subsequent pixels\n",
    "            # only difference is there is no ground truth (its a made up image)\n",
    "            \n",
    "            # bernouilli(p) => return 1 with probability p, and return 0 with probability 1-p\n",
    "            for i in range(1, MNIST_SIZE**2):\n",
    "                ith_pixel_probability = torch.sigmoid(self.models[i-1](complete_image[:, 0:i]))\n",
    "                predicted_pixel = torch.bernoulli(ith_pixel_probability)\n",
    "                complete_image[:, i:i+1] = predicted_pixel\n",
    "        # reshape image back into a vector\n",
    "        return complete_image.view(18, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of learnable parameters for this model being 52650\n"
     ]
    }
   ],
   "source": [
    "# the number of parameters of the first layer (for the second pixel) is only 1, the only weight is the first\n",
    "# pixel, for the second layers its 2, and so on and so forth, for the nth layer the number of parameters (alphas)\n",
    "# is equal to n-1\n",
    "\n",
    "# thus the number of learnable paramerters is 1 + 2 + ... + number of pixels in the image \n",
    "\n",
    "# +1 because range is not inclusive\n",
    "print(\"The number of learnable parameters for this model being {}\".format(sum(range(1, MNIST_SIZE**2 + 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvsbn = FVSBN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, device, trainloader, num_epochs=10):\n",
    "    net = net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "    img_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(Bar(trainloader)):\n",
    "            image, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            log_likelihood = fvsbn(image)\n",
    "            loss = -1 * log_likelihood\n",
    "            running_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                sample_img = net.sample()\n",
    "                img_list.append(sample_img)\n",
    "            \n",
    "            if i == 1000:\n",
    "                break\n",
    "            \n",
    "    return net, img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1001/60000: [>...............................] - ETA 8045.8s"
     ]
    }
   ],
   "source": [
    "finished_net, img_list = train(fvsbn, device, mnist_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7fdbee9710>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_list[8].cpu(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [Bayesian Networks @ Cal](https://inst.eecs.berkeley.edu/~cs188/sp12/slides/cs188%20lecture%2013%20and%2014%20--%20bayes%20nets%20representation%20and%20independence%202PP.pdf)\n",
    "- [Autoreggressive Models @ Stanford](https://deepgenerativemodels.github.io/assets/slides/cs236_lecture3.pdf)\n",
    "- [Keras Code](https://nbviewer.jupyter.org/github/ilguyi/generative.models.tensorflow.v2/blob/master/autoregressive/fvsbn.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
