{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text - Gated Neural Nets (LSTM, GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter as P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "Same RNNCell as built previously in the Text Classification introduction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # super so we inherit methods from nn.Module\n",
    "        super(RNNCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # input to hidden\n",
    "        self.Wxh = P(torch.randn(input_size, hidden_size)*0.01)\n",
    "        \n",
    "        # hidden to hidden\n",
    "        self.Whh = P(torch.randn(hidden_size, hidden_size)*0.01)\n",
    "        \n",
    "        # bias\n",
    "        self.bh = P(torch.zeros(1, hidden_size))\n",
    "\n",
    "            \n",
    "    def forward(self, input, hidden):\n",
    "        # hidden = torch.tanh(input @ self.Wxh + self.bh)\n",
    "        # would just be a multi layer perceptron\n",
    "        \n",
    "        # by adding hidden @ self.Whh we using \n",
    "        # the context of the previous hidden state\n",
    "        hidden = torch.tanh(input @ self.Wxh +  hidden @ self.Whh + self.bh)\n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "RNNs work by feeding forward the hidden state. This is to account for variable length input. Information from the previous input is fed forward, thus allowing for some sense of context. \n",
    "\n",
    "The question then being what is the limitation on the amount which can be rememebered? The issue with a classical RNN and its memory has something to do with its [gradient](!http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "In an [LSTM](!http://www.bioinf.jku.at/publications/older/2604.pdf) we first calculate 3 gates\n",
    "$$i_t = \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})$$\n",
    "$$f_t = \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{bf})$$\n",
    "$$o_t = \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho}$$\n",
    "Then \n",
    "$$g_t = \\tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{ho}$$\n",
    "\n",
    "Then from these 3 gates we derive 3 outputs\n",
    "$$c_t = f_tc_{t-1} + i_tg_t$$\n",
    "$$h_t = o_t\\tanh(c_t)$$\n",
    "[Code Referece](!https://github.com/pytorch/benchmark/blob/master/rnns/benchmarks/lstm_variants/lstm.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # input to hidden\n",
    "        self.Wxi = P(torch.randn(input_size, hidden_size)*.01)\n",
    "        self.Wxf = P(torch.randn(input_size, hidden_size)*.01)\n",
    "        self.Wxo = P(torch.randn(input_size, hidden_size)*.01)\n",
    "        self.Wxc = P(torch.randn(input_size, hidden_size)*.01)\n",
    "        \n",
    "        # hidden to hidden\n",
    "        self.Whi = P(torch.randn(hidden_size, hidden_size)*.01)\n",
    "        self.Whf = P(torch.randn(hidden_size, hidden_size)*.01)\n",
    "        self.Who = P(torch.randn(hidden_size, hidden_size)*.01)\n",
    "        self.Whc = P(torch.randn(hidden_size, hidden_size)*.01)\n",
    "        \n",
    "        # bias\n",
    "        self.bi = P(torch.zeros(1, hidden_size))\n",
    "        self.bf = P(torch.zeros(1, hidden_size))\n",
    "        self.bo = P(torch.zeros(1, hidden_size))\n",
    "        self.bc = P(torch.zeros(1, hidden_size))\n",
    "        \n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        h, c = hidden # previous h, c \n",
    "        \n",
    "        # sigmoid + linear map input, hidden -> hidden\n",
    "        i_t = torch.sigmoid(input @ self.Wxi + h @ self.Whi + self.bi)\n",
    "        f_t = torch.sigmoid(input @ self.Wxf + h @ self.Whf + self.bf)\n",
    "        o_t = torch.sigmoid(input @ self.Wxo + h @ self.Who + self.bo)\n",
    "        \n",
    "        # tanh + linear map input, hidden -> hidden\n",
    "        g_t = torch.tanh(input @ self.Wxc + h @ self.Whc + self.bc)\n",
    "        \n",
    "        # note that this is elementwise multiplication\n",
    "        # not matrix multiplication\n",
    "        c_t = c * f_t + i_t * g_t\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "        \n",
    "        return h_t, (h_t, c_t)\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size), torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Point\n",
    "One way to visually compare these 2 architectures might be seen [here](!https://web.eecs.umich.edu/~justincj/papers/understanding-rnns/KarpathyICLR2016.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/names/'\n",
    "\n",
    "# reproducability\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names Dataset\n",
    "List of names from 18 different countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFiles(path): \n",
    "    return glob.glob(path)\n",
    "\n",
    "# print(findFiles(os.path.join(DATA_DIR, 'names/*.txt')))\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles(os.path.join(DATA_DIR, 'names/*.txt')):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "        \n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size =  hidden_size\n",
    "        self.rnn = RNNCell(input_size, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.rnn(input, hidden)\n",
    "        output = self.classifier(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = LSTMCell(input_size, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, output_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        x, hidden = self.lstm(input, hidden)\n",
    "        output = self.classifier(x)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size), torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 10000\n",
    "epochs = 2\n",
    "n_hidden = 128\n",
    "rnn = RNNClassifier(n_letters, n_hidden, n_categories)\n",
    "\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.NLLLoss() # this is somehow appropriate to go with Log Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(epochs):\n",
    "    for mode in [\"train\", \"val\"]:\n",
    "        num_correct = 0\n",
    "        for iter in range(n_iters):\n",
    "            category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "            if mode == \"train\":\n",
    "                \n",
    "                hidden = rnn.initHidden()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                for i in range(line_tensor.size()[0]):\n",
    "                    output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "                loss = criterion(output, category_tensor)\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "            elif mode == \"val\":\n",
    "                with torch.no_grad():\n",
    "                    hidden = rnn.initHidden()\n",
    "\n",
    "                    for i in range(line_tensor.size()[0]):\n",
    "                        output, hidden = rnn(line_tensor[i], hidden)\n",
    "                        \n",
    "                    guess, guess_i = categoryFromOutput(output)\n",
    "                    if guess == category:\n",
    "                        num_correct += 1\n",
    "    print(\"Percent Correct {} on Epoch {}\".format(num_correct/n_iters, ep+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 10000\n",
    "epochs = 2\n",
    "n_hidden = 128\n",
    "lstm = LSTMClassifier(n_letters, n_hidden, n_categories)\n",
    "\n",
    "optimizer = optim.SGD(lstm.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.NLLLoss() # this is somehow appropriate to go with Log Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(epochs):\n",
    "    for mode in [\"train\", \"val\"]:\n",
    "        num_correct = 0\n",
    "        for iter in range(n_iters):\n",
    "            category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "            if mode == \"train\":\n",
    "                \n",
    "                hidden = lstm.initHidden()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                for i in range(line_tensor.size()[0]):\n",
    "                    output, hidden = lstm(line_tensor[i], hidden)\n",
    "\n",
    "                loss = criterion(output, category_tensor)\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "            elif mode == \"val\":\n",
    "                with torch.no_grad():\n",
    "                    hidden = lstm.initHidden()\n",
    "\n",
    "                    for i in range(line_tensor.size()[0]):\n",
    "                        output, hidden = lstm(line_tensor[i], hidden)\n",
    "                        \n",
    "                    guess, guess_i = categoryFromOutput(output)\n",
    "                    if guess == category:\n",
    "                        num_correct += 1\n",
    "    print(\"Percent Correct {} on Epoch {}\".format(num_correct/n_iters, ep+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
