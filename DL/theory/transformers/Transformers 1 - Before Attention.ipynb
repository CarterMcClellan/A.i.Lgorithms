{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Sequence to Sequence Modeling\n",
    "seq2seq with RNNs is simple\n",
    "```python\n",
    "y, s = '<s>', encoder(x)\n",
    "for _ in range(N):\n",
    "    y, s = decoder(y, s)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Lib\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tokenization\n",
    "import spacy \n",
    "\n",
    "# Loading Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Torch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Dataloader Custom Module\n",
    "from sample_dataloader import get_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Dataset from [here](https://pytorch.org/text/stable/_modules/torchtext/datasets/iwslt2016.html), key tokens:\n",
    "```python\n",
    "'<unk>' unkown token\n",
    "'<pad>' padding token\n",
    "'<bos>' beginning of sentence token\n",
    "'<eos>' end of sentence token\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.path.join(Path(os.getcwd()).parent.parent.parent, \"Datasets/\")\n",
    "gpu = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/opt/conda/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/opt/conda/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "trainset, validset, testset, de_vocab, en_vocab = get_dataloaders(batch_size=128, device=gpu, data_root=data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all these indices are the same for french and english\n",
    "PAD_IDX = de_vocab['<pad>']\n",
    "SOS_IDX = de_vocab['<sos>']\n",
    "EOS_IDX = de_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic RNN Architecture\n",
    "Lets first solve our machine translation problem with a simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, trg_vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.trg_vocab_size = trg_vocab_size \n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, self.trg_vocab_size).to(self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            outputs[t] = output\n",
    "            \n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            top1 = output.argmax(1) \n",
    "    \n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(de_vocab)\n",
    "OUTPUT_DIM = len(en_vocab)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, gpu, OUTPUT_DIM).to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7854, 128)\n",
       "    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 128)\n",
       "    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=256, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model weights\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,117,317 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip=1, num_epochs=40):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for _ in range(num_epochs):\n",
    "        for i, batch in tqdm(enumerate(iterator), desc=\"iteration\"):\n",
    "            src = batch.src\n",
    "            trg = batch.trg \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(src, trg)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            # clip the gradients to prevent them from exploding (a common issue in RNNs)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            optimizer.step()\n",
    "                    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 0it [00:00, ?it/s]/opt/conda/lib/python3.8/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "iteration: 227it [00:16, 13.69it/s]\n",
      "iteration: 227it [00:16, 14.15it/s]\n",
      "iteration: 227it [00:16, 14.05it/s]\n",
      "iteration: 227it [00:16, 14.15it/s]\n",
      "iteration: 227it [00:16, 14.06it/s]\n",
      "iteration: 227it [00:15, 14.30it/s]\n",
      "iteration: 227it [00:15, 14.38it/s]\n",
      "iteration: 227it [00:16, 13.99it/s]\n",
      "iteration: 227it [00:16, 14.02it/s]\n",
      "iteration: 227it [00:16, 13.99it/s]\n",
      "iteration: 227it [00:16, 14.17it/s]\n",
      "iteration: 227it [00:16, 14.04it/s]\n",
      "iteration: 227it [00:15, 14.26it/s]\n",
      "iteration: 227it [00:16, 14.06it/s]\n",
      "iteration: 227it [00:16, 14.05it/s]\n",
      "iteration: 227it [00:15, 14.24it/s]\n",
      "iteration: 227it [00:15, 14.28it/s]\n",
      "iteration: 227it [00:15, 14.19it/s]\n",
      "iteration: 227it [00:16, 14.00it/s]\n",
      "iteration: 227it [00:15, 14.29it/s]\n",
      "iteration: 227it [00:15, 14.23it/s]\n",
      "iteration: 227it [00:15, 14.25it/s]\n",
      "iteration: 227it [00:15, 14.19it/s]\n",
      "iteration: 227it [00:15, 14.38it/s]\n",
      "iteration: 227it [00:15, 14.42it/s]\n",
      "iteration: 227it [00:15, 14.47it/s]\n",
      "iteration: 227it [00:16, 14.14it/s]\n",
      "iteration: 227it [00:15, 14.28it/s]\n",
      "iteration: 227it [00:15, 14.44it/s]\n",
      "iteration: 227it [00:15, 14.36it/s]\n",
      "iteration: 227it [00:15, 14.32it/s]\n",
      "iteration: 227it [00:15, 14.23it/s]\n",
      "iteration: 227it [00:15, 14.35it/s]\n",
      "iteration: 227it [00:15, 14.41it/s]\n",
      "iteration: 227it [00:15, 14.33it/s]\n",
      "iteration: 227it [00:15, 14.35it/s]\n",
      "iteration: 227it [00:15, 14.37it/s]\n",
      "iteration: 227it [00:15, 14.42it/s]\n",
      "iteration: 227it [00:15, 14.37it/s]\n",
      "iteration: 227it [00:16, 14.15it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "model, losses = train(model, trainset, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7f9c042d00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=list(range(len(losses))), y=losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_2_str(tensor, vocab=de_vocab.itos):\n",
    "    return \" \".join([vocab[int(token)] for token in tensor if vocab[int(token)] not in ['<eos>', '<pad>', '.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "  Output: <unk> a shirtless man man wearing sunglasses and a , walking down path , in a cloudy day  \n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Expected: <sos> a shirtless black man wearing sunglasses and jogging pants along a park path near a waterway\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sample = next(iter(trainset))\n",
    "    src, trg = sample.src, sample.trg\n",
    "    output = model(src, trg)\n",
    "    output_tensor = output.argmax(2)[:, 0]\n",
    "    target_tensor = trg[:, 0]\n",
    "    \n",
    "    output = tensor_2_str(output_tensor, en_vocab.itos)\n",
    "    expected = tensor_2_str(target_tensor, en_vocab.itos)\n",
    "    N = max(len(output), len(expected)) + len(\"Expected: \")\n",
    "    \n",
    "    print(\"=\"*N)\n",
    "    print(\"Output: {}\".format(output).center(N))\n",
    "    print(\"=\"*N)\n",
    "    \n",
    "    print(\"=\"*N)\n",
    "    print(\"Expected: {}\".format(expected).center(N))\n",
    "    print(\"=\"*N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
